import os
import streamlit as st
from pinecone import Pinecone
from sentence_transformers import SentenceTransformer
from openai import OpenAI

PINECONE_API_KEY = os.environ.get("PINECONE_API_KEY")
OPENAI_API_KEY   = os.environ.get("OPENAI_API_KEY")

pc = Pinecone(api_key=PINECONE_API_KEY)
index = pc.Index("seu-chatbot")

model = SentenceTransformer(
    "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
)

client = OpenAI(api_key=OPENAI_API_KEY)

def pinecone_search(query, k=5):
    q_emb = model.encode(query).tolist()

    res = index.query(
        vector=q_emb,
        top_k=k,
        include_metadata=True
    )

    results = []
    for m in res["matches"]:
        results.append({
            "score": m["score"],
            "text": m["metadata"]["text"],
            "source": m["metadata"]["source"]
        })

    return results

# RAG + LLM
def build_context(results):
    ctx = ""
    for r in results:
        ctx += f"\n\n--- Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø±: {r['source']} ---\n{r['text']}"
    return ctx


def answer_with_llm(query, results):
    prompt = f"""
Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†ØµÙˆØµ ÙÙ‚Ø·.
Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©ØŒ Ù‚Ù„:
"Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª".

Ø§Ù„Ø³Ø¤Ø§Ù„:
{query}

Ø§Ù„Ù†ØµÙˆØµ:
{build_context(results)}

Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¬Ø§Ù…Ø¹ÙŠ Ø¯Ù‚ÙŠÙ‚ Ø¬Ø¯Ù‹Ø§."},
            {"role": "user", "content": prompt}
        ]
    )

    return response.choices[0].message.content

st.set_page_config(page_title="SEU Chatbot", page_icon="ğŸ“")

st.title("SEU Chatbot")

query = st.text_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§")

if st.button("Ø¥Ø±Ø³Ø§Ù„"):
    if not query.strip():
        st.warning("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„ Ø£ÙˆÙ„Ù‹Ø§")
    else:
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª..."):
            results = pinecone_search(query, k=5)
            answer = answer_with_llm(query, results)

        st.subheader("Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©")
        st.write(answer)

        # st.markdown("---")
        # with st.expander("ğŸ“„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©"):
        #     for r in results:
        #         st.write(f"**{r['source']}** â€” Score: {r['score']:.3f}")
        #         st.write(r["text"][:700])
        #         st.write("---")



